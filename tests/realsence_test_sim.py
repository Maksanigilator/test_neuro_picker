import pybullet as p
import pybullet_data
import time
import numpy as np
import cv2

# 1) ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ÑÑ Ğº PyBullet Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ GUI
physicsClient = p.connect(p.GUI)
p.setAdditionalSearchPath(pybullet_data.getDataPath())  # Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ plane.urdf

# 2) Ğ—Ğ°Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸
p.setGravity(0, 0, -9.81)
timeStep = 1.0/240.0
p.setTimeStep(timeStep)

# 3) Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Â«Ğ¿Ğ¾Ğ»Â»
planeId = p.loadURDF("plane.urdf")

# 4) Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ñ€Ğ¾Ğ±ĞºĞ¸ (Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ĞµĞ¿Ğ¸Ğ¿ĞµĞ´Ğ°)
def create_box(size, mass, position):
    # size = [dx, dy, dz] â€” Ğ³Ğ°Ğ±Ğ°Ñ€Ğ¸Ñ‚Ñ‹ ĞºĞ¾Ñ€Ğ¾Ğ±ĞºĞ¸
    collision_shape = p.createCollisionShape(p.GEOM_BOX, halfExtents=[s/2 for s in size])
    visual_shape    = p.createVisualShape(p.GEOM_BOX, halfExtents=[s/2 for s in size],
                                          rgbaColor=[1,1,1,1])
    body = p.createMultiBody(baseMass=mass,
                             baseCollisionShapeIndex=collision_shape,
                             baseVisualShapeIndex=visual_shape,
                             basePosition=position)
    return body


# 5) RealSense ĞºĞ°Ğ¼ĞµÑ€Ğ° ĞºĞ»Ğ°ÑÑ
class RealSenseCamera:
    def __init__(self, position, target, up_vector):
        self.position = position
        self.target = target
        self.up_vector = up_vector

        # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ ĞºĞ°Ğ¼ĞµÑ€Ñ‹ RealSense D435
        self.width = 640
        self.height = 480
        self.fov = 69.4  # Ğ¿Ğ¾Ğ»Ğµ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğ°Ğ»Ğ¸ Ğ² Ğ³Ñ€Ğ°Ğ´ÑƒÑĞ°Ñ…
        self.aspect = self.width / self.height
        self.near = 0.1
        self.far = 5.0

        # ĞœĞ°Ñ‚Ñ€Ğ¸Ñ†Ñ‹ Ğ¿Ñ€Ğ¾ĞµĞºÑ†Ğ¸Ğ¸ Ğ¸ Ğ²Ğ¸Ğ´Ğ°
        self.projection_matrix = p.computeProjectionMatrixFOV(
            self.fov, self.aspect, self.near, self.far
        )

        self.view_matrix = p.computeViewMatrix(
            self.position, self.target, self.up_vector
        )

        # Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹ Ğ² ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸
        self.create_camera_visualization()

    def create_camera_visualization(self):
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹ Ğ² Ğ²Ğ¸Ğ´Ğµ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ³Ğ¾ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°"""
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¼Ğ°Ğ»ĞµĞ½ÑŒĞºĞ¸Ğ¹ ĞºÑƒĞ± Ğ´Ğ»Ñ Ğ¾Ğ±Ğ¾Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹
        collision_shape = p.createCollisionShape(p.GEOM_BOX, halfExtents=[0.02, 0.05, 0.02])
        visual_shape = p.createVisualShape(p.GEOM_BOX, halfExtents=[0.02, 0.05, 0.02],
                                           rgbaColor=[0.2, 0.2, 0.8, 1.0])  # ÑĞ¸Ğ½Ğ¸Ğ¹ Ñ†Ğ²ĞµÑ‚
        self.camera_body = p.createMultiBody(baseMass=0,  # ÑÑ‚Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¾Ğ±ÑŠĞµĞºÑ‚
                                             baseCollisionShapeIndex=collision_shape,
                                             baseVisualShapeIndex=visual_shape,
                                             basePosition=self.position)

    def get_rgb_image(self):
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ RGB Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹"""
        width, height, rgb_img, depth_img, seg_img = p.getCameraImage(
            width=self.width,
            height=self.height,
            viewMatrix=self.view_matrix,
            projectionMatrix=self.projection_matrix,
            renderer=p.ER_BULLET_HARDWARE_OPENGL
        )

        # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ OpenCV (BGR)
        rgb_array = np.array(rgb_img, dtype=np.uint8).reshape((height, width, 4))
        rgb_array = rgb_array[:, :, :3]  # ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ°Ğ»ÑŒÑ„Ğ° ĞºĞ°Ğ½Ğ°Ğ»
        bgr_array = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2BGR)

        return bgr_array

    def get_depth_image(self):
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ depth Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹"""
        width, height, rgb_img, depth_img, seg_img = p.getCameraImage(
            width=self.width,
            height=self.height,
            viewMatrix=self.view_matrix,
            projectionMatrix=self.projection_matrix,
            renderer=p.ER_BULLET_HARDWARE_OPENGL
        )

        # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ depth Ğ±ÑƒÑ„ĞµÑ€ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ
        depth_array = np.array(depth_img, dtype=np.float32).reshape((height, width))

        # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ· depth buffer Ğ² Ğ¼ĞµÑ‚Ñ€Ñ‹
        depth_real = self.far * self.near / (self.far - (self.far - self.near) * depth_array)

        # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
        depth_real = np.clip(depth_real, self.near, self.far)

        return depth_real

    def get_point_cloud(self):
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¾Ğ±Ğ»Ğ°ĞºĞ¾ Ñ‚Ğ¾Ñ‡ĞµĞº"""
        rgb_img = self.get_rgb_image()
        depth_img = self.get_depth_image()

        # Ğ’Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ ĞºĞ°Ğ¼ĞµÑ€Ñ‹
        fx = fy = self.width / (2 * np.tan(np.radians(self.fov) / 2))
        cx, cy = self.width / 2, self.height / 2

        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¾Ğ±Ğ»Ğ°ĞºĞ¾ Ñ‚Ğ¾Ñ‡ĞµĞº
        points = []
        colors = []

        for v in range(0, self.height, 5):  # Ğ¿Ñ€Ğ¾Ñ€ĞµĞ¶Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
            for u in range(0, self.width, 5):
                z = depth_img[v, u]
                if z > self.near and z < self.far:
                    x = (u - cx) * z / fx
                    y = (v - cy) * z / fy

                    # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ¸Ğ· ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚ ĞºĞ°Ğ¼ĞµÑ€Ñ‹ Ğ² Ğ¼Ğ¸Ñ€Ğ¾Ğ²ÑƒÑ
                    # Ğ£Ğ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹, ÑĞ¼Ğ¾Ñ‚Ñ€ÑÑ‰ĞµĞ¹ Ğ²Ğ½Ğ¸Ğ·
                    world_x = self.position[0] + x
                    world_y = self.position[1] + y
                    world_z = self.position[2] - z

                    points.append([world_x, world_y, world_z])
                    colors.append(rgb_img[v, u])

            return np.array(points), np.array(colors)


# 6) Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ ĞºÑƒÑ‡Ñƒ Ğ¸Ğ· 10 ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ñ… ĞºĞ¾Ñ€Ğ¾Ğ±Ğ¾Ğº
np.random.seed(0)
boxes = []
for i in range(10):
    size = [0.1 + 0.1 * np.random.rand(), 0.1 + 0.1 * np.random.rand(), 0.1 + 0.1 * np.random.rand()]
    mass = 0.5 + np.random.rand() * 0.5
    # ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ² Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ñ… ĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ° 0.5Ã—0.5 Ğ¼, Ğ²Ñ‹ÑĞ¾Ñ‚Ğ° 1.5 Ğ¼
    pos = [0.0 + (np.random.rand() - 0.5) * 0.5,
           0.0 + (np.random.rand() - 0.5) * 0.5,
           1.0 + np.random.rand() * 0.5]
    box_id = create_box(size, mass, pos)
    boxes.append(box_id)

# 7) Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ RealSense ĞºĞ°Ğ¼ĞµÑ€Ñƒ Ğ½Ğ°Ğ´ ĞºĞ¾Ñ€Ğ¾Ğ±ĞºĞ°Ğ¼Ğ¸
camera_position = [0.0, 0.0, 2.0]  # 2 Ğ¼ĞµÑ‚Ñ€Ğ° Ğ½Ğ°Ğ´ Ñ†ĞµĞ½Ñ‚Ñ€Ğ¾Ğ¼
camera_target = [0.0, 0.0, 0.0]  # ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚ Ğ² Ñ†ĞµĞ½Ñ‚Ñ€ ĞºÑƒÑ‡Ğ¸
up_vector = [0.0, 1.0, 0.0]  # Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹

realsense_camera = RealSenseCamera(camera_position, camera_target, up_vector)

# ğŸ˜ Ğ”Ğ°ĞµĞ¼ ĞºĞ¾Ñ€Ğ¾Ğ±ĞºĞ°Ğ¼ ÑƒĞ¿Ğ°ÑÑ‚ÑŒ â€” Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ñ‹ÑÑÑ‡ ÑˆĞ°Ğ³Ğ¾Ğ² ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸
print("ĞšĞ¾Ñ€Ğ¾Ğ±ĞºĞ¸ Ğ¿Ğ°Ğ´Ğ°ÑÑ‚...")
for _ in range(240 * 5):  # ~5 ÑĞµĞºÑƒĞ½Ğ´ Ğ¿Ñ€Ğ¸ 240 Ğ“Ñ†
    p.stepSimulation()
    time.sleep(timeStep)

# 9) ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ†Ğ¸ĞºĞ» Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹
print("ĞšÑƒÑ‡Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°. ĞšĞ°Ğ¼ĞµÑ€Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚. ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ 'q' Ğ² Ğ¾ĞºĞ½Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°.")
frame_count = 0

try:
    while True:
        p.stepSimulation()
        time.sleep(timeStep)

        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 10 ĞºĞ°Ğ´Ñ€Ğ¾Ğ² (Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸)
        if frame_count % 10 == 0:
            # RGB Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
            rgb_image = realsense_camera.get_rgb_image()
            cv2.imshow('RealSense RGB', rgb_image)

            # Depth Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ (Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ)
            depth_image = realsense_camera.get_depth_image()
            depth_normalized = cv2.normalize(depth_image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
            depth_colored = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_JET)
            cv2.imshow('RealSense Depth', depth_colored)

            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ¶Ğ°Ñ‚Ğ¸Ğµ ĞºĞ»Ğ°Ğ²Ğ¸ÑˆĞ¸
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break

        frame_count += 1

        # ĞšĞ°Ğ¶Ğ´Ñ‹Ğµ 100 ĞºĞ°Ğ´Ñ€Ğ¾Ğ² Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ¾Ğ±Ğ»Ğ°ĞºĞµ Ñ‚Ğ¾Ñ‡ĞµĞº
        if frame_count % 500 == 0:
            points, colors = realsense_camera.get_point_cloud()
            print(f"ĞĞ±Ğ»Ğ°ĞºĞ¾ Ñ‚Ğ¾Ñ‡ĞµĞº ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ {len(points)} Ñ‚Ğ¾Ñ‡ĞµĞº")

except KeyboardInterrupt:
    pass

# Ğ—Ğ°ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¾ĞºĞ½Ğ° OpenCV
cv2.destroyAllWindows()
p.disconnect()
print("Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°.")

